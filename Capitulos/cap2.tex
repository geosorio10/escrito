\chapter{El Entrelazamiento y La Mecánica Estadística} \label{cap:2}

La mecánica clásica nos habla de un sistema físico definido que para todos los tiempos está especificado. Este sistema evoluciona de manera determinista dadas las ecuaciones de movimiento. Al tratar con  sistemas termodinámicos, aunque se trate de un sistema clásico, éste puede mostrar propiedades que dependan de promedios estadísticos \cite{CallenThermo}. La conexión que hay entre el determinismo y estas probabilidades es una discusión que no ha sido resuelta, dado que todas las soluciones hasta ahora propuestas han tenido fallas, como, por ejemplo, las ideas dadas por Gibbs expuestas anteriormente. Los métodos típicos requieren hablar de promedios de ensamble, promedios temporales y aleatoriedad. Todos estos conceptos siguen siendo muy debatidos y no parecen solucionar ninguna pregunta \cite{TodaStat}. Por eso, recientemente se han estado buscando nuevos fundamentos para la mecánica estadística.
\\
La mecánica estadística tiene como base el postulado de probabilidades iguales; éste es dado por la ignorancia subjetiva que el observador tiene del sistema. Aunque la mecánica estadística no tiene problemas al comparar sus resultados teóricos con los experimentales, el cimiento filosófico en el que ésta reposa ha dado mucho de qué hablar, por lo que desde los inicios de la teoría han surgido posturas diferentes que no han podido ser unificadas. 
\\
En este capítulo se seguirá el trabajo de Popescu \textit{et al}  \cite{Popescu2006} y se mostrará una posible luz sobre el problema de unificar las perspectivas de la mecánica estadística. La idea principal que se quiere presentar aquí es cómo se puede reemplazar el postulado de probabilidades iguales por un principio canónico general basado en el entrelazamiento cuántico. Al poner el entrelazamiento cuántico como nuevo cimiento, ya no se tienen probabilidades subjetivas sino objetivas dadas por la teoría cuántica. Este nuevo enfoque permite evitar problemas con la ignorancia subjetiva, pero también esquiva el problema de la ergodicidad, gracias a lo cual se puede ver un fundamento más claro y sólido. 
\\
Este capítulo solo se enfocará en mostrar cómo la mayoría de los estados del universo están termalizados sin hablar en ningún momento de la evolución de estos estados. Si, en general, los estados del universo están termalizados, se esperaría que cualquier evolución lleve los estados al equilibrio. En el siguiente capítulo se darán especificaciones sobre esta conjetura junto con algunos detalles que evidencian las complicaciones que acarrea formalizar las ideas intuitivas que se tienen sobre el equilibrio.
\\
\section{Herramientas de la Teoría Cuántica}
La mecánica cuántica dada por Schrödinger usa el formalismo del vector de estado. Las herramientas entregadas por el vector de estado son útiles para algunos problemas, pero este formalismo no siempre es útil en casos particulares. Es por esto que se usa el formalismo de la matriz densidad u operador densidad cuando se habla de un sistema compuesto por un subsistema y su ambiente. Debido al entrelazamiento que existe ente el subsistema y su ambiente, no se puede especificar un estado individual para el subsistema. Las herramientas proporcionadas por el operador densidad permiten representar las estadísticas de las medidas de uno de los componentes del sistema \cite{Decoherence}.
\\

\subsection{Operador Densidad}
Para comprender qué es el operador densidad se debe empezar por responder cuándo se tiene el máximo conocimiento posible de un estado cuántico. Cuánticamente, si el estado $\ket{\psi}$ da toda la información posible de un sistema, se le llama estado puro. Para especificar cuál es el operador densidad de un sistema, se supone que el sistema cuántico puede estar en un estado puro, $\ket{\psi_{i}}$ para $i=1,2,...$. Cada estado posible del sistema tiene una probabilidad correspondiente, $p_{i}>0$ y $\sum_{i} p_{i}$. Luego el operador densidad para el sistema es:
\begin{equation}
\rho \equiv \sum_{i} p_{i} \ket{\psi_{i}}\bra{\psi_{i}}.
\end{equation}
En caso de que sólo haya un estado posible se tiene el operador densidad para un estado puro $\rho= \ket{\psi}\bra{\psi}$. Entonces se puede hablar de un ensamble de estados puros $ \{ p_{i} | \ket{\psi_{i}} \} $  siendo el operador densidad la distribución clásica de probabilidad de matrices de estados puros. Nótese que se puede usar de manera similar el nombre de operador densidad y de matriz densidad, ésta es la usanza de la literatura. 
\\
El operador densidad también puede ser especificado por las siguientes propiedades: 

\begin{enumerate}
\item $\rho$ tiene traza igual a uno, $\Tr(\rho)=1$.

\item $\rho$ es un operador positivo si: $\ket{\phi}$ es un vector arbitrario, luego $\bra{\psi}\rho\ket{\psi} \geq 0$.
\end{enumerate}
Ya con esta breve introducción se pueden reescribir los postulados de la mecánica cuántica en este formalismo, siguiendo a \cite{NielsenInformation}:
\\
\textbf{Postulado 1}: Se puede asociar un espacio de Hilbert a un sistema físico aislado. El sistema está descrito completamente por el operador densidad que actúa sobre el espacio de Hilbert del sistema. Si un sistema cuántico está en el estado $\rho_{i}$ con probabilidad $p_{i}$, el operador de densidad del sistema es $\sum_{i} p_{i} \rho_{i}$.
\\

\textbf{Postulado 2}: La evolución de un sistema cuántico cerrado está descrita por una transformación unitaria. Esto es, el estado $\rho$ del sistema, en el tiempo $t_{0}$, está relacionado con el estado $\rho'$ del sistema para el tiempo $t$ por un operador unitario $U$, el cual depende solo de los tiempos $t_{0}$ y $t$. 
\begin{equation}
\rho' = U \rho U^{\dagger}.
\end{equation}
\\

\textbf{Postulado 3}: Las medidas cuánticas están descritas por un conjunto de operadores $ \{  M_{m} \}$. Estos operadores actúan en el espacio de Hilbert del sistema. El índice $m$ habla de los posibles resultados de una medida al hacer un experimento. Si se tiene el estado del sistema $\rho$ inmediatamente antes de la medida, la probabilidad que el resultado $m$ ocurra es:
\begin{equation}
p(m)= \Tr (M^{\dagger}_{m}M_{m} \rho),
\end{equation}
y el estado del sistema luego de una medición es
\begin{equation}
\frac{M_{m} \rho M_{m}^{\dagger}}{\Tr(M^{\dagger}_{m}M_{m} \rho)}.
\end{equation}
Los operadores $\{  M_{m} \}$ satisfacen,
\begin{equation}
\sum_{m} M^{\dagger}_{m}M_{m} = I.
\end{equation}
\textbf{Postulado 4}: El espacio de un sistema físico compuesto es el producto tensorial de cada espacio de los componentes del sistema. Si  hay $N$ sistemas y cada sistema es preparado en el estado $\rho_{i}$, con el índice recorriendo cada sistema, el sistema total está representado por $\rho_{1} \otimes \rho_{2} \otimes ...\otimes \rho_{n}$.
\\
\\
Estos son los postulados de la mecánica cuántica desde la perspectiva del operador densidad. Estos postulados son análogos a la perspectiva del vector de estado. Pero se debe ver un poco más en detalle el postulado 3, éste habla de las mediciones cuánticas con mayor generalidad. Habitualmente, al introducir la mecánica cuántica sólo se habla de medidas proyectivas, las cuales tienen muchas restricciones y no abarcan todas las posibilidades de medición.
\\	
Se puede demostrar que las mediciones proyectivas junto con los demás axiomas de la cuántica son semejantes a las medidas generales \cite{NielsenInformation}. Entonces, si existe una equivalencia entre estos dos tipos de mediciones, ¿por qué preocuparse por un esquema más general? Porque las mediciones generales tienen menos restricciones que las medidas proyectivas, lo cual da una variedad de propiedades que las medidas proyectivas no tienen. Además, en algunos problemas concernientes a la teoría cuántica de la información es necesario usar mediciones generales, como por ejemplo, para la manera óptima de distinguir entre un conjunto de estados cuánticos.
\\
Pero hay una ventaja que tienen  la mediciones generales sobre las proyectivas, es lo que se conoce como \textit{repetibilidad}. Las medidas proyectivas tienen repetibilidad, puesto que si se tiene un estado inicial $\ket{\psi}$, al hacer la primera medida se encuentra que $\ket{\psi_{m}}=\frac{P_{m}\ket{\psi}}{\sqrt{\bra{\psi}P_{m}\ket{\psi}}}$. Operando otra vez a $\ket{\psi_{m}}$ con $P_{m}$, el estado no cambia, entonces $\bra{\psi_{m}}P_{m}\ket{\psi_{m}}=1$. Esto significa que si se repite la medición muchas veces, se seguirá en el mismo estado \cite{VedralInformation}. Pero esto no es cierto para todos los experimentos. Por ejemplo, en el experimento de la doble rendija para conocer la posición de un fotón al pasar por una placa, es imposible conocer la posición del fotón una segunda vez. Entonces se debe recurrir a las mediciones generales. De esta mediciones generales hay un caso particular que es usado en la teoría cuántica de la información, este caso se llama medidas POVM (Positive Operator-Valued Measure). Estas medidas son de utilidad cuando sólo se quiere saber la probabilidad de que un resultado se dé, sin la necesidad de saber el estado del sistema luego de la medida \cite{NielsenInformation}.
Por el postulado 3 se sabe que la probabilidad de que el resultado m salga viene dado por $p(m)= \Tr (M^{\dagger}_{m}M_{m} \rho)$. Si se define:
\begin{equation}
E_{m} \equiv M^{\dagger}_{m}M_{m}.
\end{equation}
Se puede demostrar fácilmente que $E_{m}$ es un operador positivo y cumple con $\sum_{m} E_{m}=I$. El conjunto completo de $ \{ E_{m}\}$ se conoce como POVM, y cada $E_{m}$ es un elemento asociado a POVM. Las mediciones proyectivas hacen parte de POVM, sea $P_{m}$ un proyector tal que $P_{m}P_{n}= \delta_{mn}P_{m}$ y $\sum_{m}P_{m}=I$. Sólo para este caso los elementos POVM son los mismos operadores de medición, ya que $E_{m}=P_{m}^{\dagger}P_{m}=P_{m}$.
\\
Estas mediciones generales permiten liberarse de restricciones impuestas por las mediciones proyectivas y, con esto, se pueden analizar situaciones donde medir más de una vez afecta el sistema. Hasta ahora se ha introducido el formalismo del operador densidad y se ha explicado cómo puede sustituir el vector de estado. Pero no se ha exhibido su poder en casos donde el vector de estado no dice mucho. La siguiente sección desarrollará un método bastante importante en el caso de sistemas entrelazados. Este método será central en el análisis subsiguiente sobre el entrelazamiento y la mecánica estadística.

\subsection{Operador Densidad Reducido}

Ahora se plantea la siguiente situación: se tiene un sistema $A$ que está correlacionado cuánticamente con el sistema $B$. Esto quiere decir que el sistema completo $AB$ puede estar dado por un estado puro, pero no se puede describir individualmente el sistema $A$; entonces, si solo se tiene acceso al sistema $A$ pero no al $B$, ¿cómo se puede modelar matemáticamente la información que sólo es posible de extraer de mediciones locales en $A$? Aquí se usa el operador densidad reducido; este se define como
\begin{equation}
\rho_{A} \equiv \Tr_{B}(\rho_{AB}).
\end{equation}
La traza es tomada únicamente en una base del espacio de Hilbert $\mathcal{H}_{B}$ del sistema $B$. Esta operación puede ser interpretada como si se estuviera promediando sobre todos los grados de libertad del sistema al que no se tiene acceso. A esta operación se le llama la traza parcial sobre $B$. Para ver la utilidad que tiene este operador se verá un ejemplo sencillo que se puede generalizar fácilmente.
Se tiene el estado de algún sistema compuesto por $A$ y $B$ dado por la función de onda $\Phi$:
\begin{equation}
\Phi = \frac{1}{\sqrt{2}} (\ket{a_{1}}\ket{b_{1}}+\ket{a_{2}}\ket{b_{2}});
\end{equation}
este es un típico ejemplo de una función de onda donde los subsistemas $A$ y $B$ están entrelazados \cite{SusskindQuantum}. Los estados $\ket{a_{1}}$, $\ket{b_{1}}$,$\ket{a_{2}}$, $\ket{b_{2}}$ no son necesariamente ortogonales. La matriz de densidad es claramente:
\begin{equation}
\ket{\Phi}\bra{\Phi} = \frac{1}{2}\sum_{ij=1}^{2} \ket{a_{i}}\bra{a_{j}} \ket{b_{i}}\bra{b_{j}} .
\end{equation}
Sea $ \{ \ket{\psi_{k}} \} $ una base ortonormal en $\mathcal{H}_{A}$ y $ \{ \ket{\phi_{l}} \} $ una base ortonormal en $\mathcal{H}_{B}$. Considerando mediciones que sólo afecten al sistema $A$ se puede representar esta acción como $M=M_{A} \otimes I_{B}$, donde $I_{B}$ es el operador identidad en el espacio de Hilbert de $B$. Siguiendo la idea de responder si se puede extraer información del sistema solo conociendo las mediciones locales en $A$, entonces se hace el siguiente razonamiento:
\begin{align}
\langle M \rangle &=  \Tr(\rho M)\\
\quad &=\sum_{kl} \bra{\phi_{l}}\bra{\psi_{k}}\rho(M_{A} \otimes I_{B})\ket{\psi_{k}} \ket{\phi_{l}}\\
\quad &=\sum_{k}\bra{\psi_{k}}  \Bigg( \sum_{l=1} \bra{\phi_{l}} \rho\ket{\phi_{l}} \Bigg) M_{A}\ket{\psi_{k}}\\
\quad &=\sum_{k}\bra{\psi_{k}} ( \Tr_{B}(\rho) )  M_{A}\ket{\psi_{k}}\\
\quad &=\sum_{k}\bra{\psi_{k}} \rho_{A}  M_{A}\ket{\psi_{k}}\\
\quad &= \Tr_{A} (\rho_{A} M_{A}).
\end{align}
Aquí $\rho_{A}$ es la matriz reducida definida al inicio de esta subsección. El ejemplo se puede expandir para sistemas con $N$ subsistemas entrelazados. Se tiene ahora $N$ componentes del sistema y solo se puede hacer mediciones en el componente $i$. El operador que describe estas mediciones sería $M= I_{1}\otimes I_{2} ... \otimes I_{i-1} \otimes M_{i} \otimes I_{i+1}\otimes .... \otimes I_{N}$. Ahora la matriz de densidad reducida para el sistema $i$ es
\begin{equation}
\rho_{i}= \Tr_{1,...,i-1,i+1,...,N}(\rho).
\end{equation}
Con esto y siguiendo el ejemplo anterior se puede demostrar que  \cite{Decoherence}
\begin{equation}
\langle M \rangle = \Tr(\rho M)=\Tr_{i}(\rho_{i} M_{i}).
\end{equation}
Entonces si se conoce el estado del sistema total y solo es posible hacer mediciones en un subsistema, aún así, gracias al formalismo del operador densidad, se pueden hallar las estadísticas de las mediciones. Es importante aclarar que aunque se tenga un operador de densidad reducido para el sistema $A$, esto no significa que se haya descrito el sistema de manera individual. El operador densidad es solo una herramienta matemática para sacar las estadísticas de las mediciones. Se vio el poder que tiene el formalismo del operador densidad pero aún se puede construir más en base a éste. La siguiente sección formulará una pregunta que se responderá usando las herramientas cuánticas mostradas hasta ahora.
\subsection{Distancia de Traza}

Los métodos mostrados anteriormente tienen, por lo general, una herramienta única al momento de solucionar el problema. Ahora, se encuentra con la pregunta ¿qué tan cerca están dos estado cuánticos? La respuesta puede ser dada por varias definiciones de distancias, pero la que se usará aquí será la distancia de traza.
\\
Una pregunta relacionada con la cercanía de los estados cuánticos es ¿qué quiere decir que dos mensajes diferentes tengan la misma información? En la teoría clásica de la información esto recae en poder diferenciar dos distribuciones de probabilidad. Pero como ya se había advertido esta respuesta no es única, existen diferentes medidas como la fidelidad o la distancia de Kullback–Leibler. Dependiendo del fin, será deseable una sobre las demás.
\\
Se tienen dos distribuciones de probabilidad $\{ p_{x} \}$ y $\{ q_{x} \}$. La distancia de traza clásica viene dada por:
\begin{equation}
D(p_{x},q_{x})\equiv \frac{1}{2} \sum_{x}|p_{x}-q_{x}|.
\end{equation}
También se conoce como la distancia $L_{1}$ o la distancia de Kolmogorov. Esta distancia también se puede escribir de la siguiente manera 
\begin{equation}
D(p_{x},q_{x})= \max_{S} \big| p(S)-q(S) \big| = \max_{S} \Bigg| \sum_{x \in S}p_{x}-\sum_{x \in S}q_{x} \Bigg|.
\end{equation}
\\
Donde la maximización es sobre todos los subconjuntos $S$ de los indices $\{ x \}$ \cite{NielsenInformation}. Aunque estas igualdades puedan ser complicadas para hacer cálculos, es posible tener alguna intuición sobre estas ecuaciones. La distancia de traza es la maximización de las diferencias entre la probabilidad que el evento $S$ ocurra de acuerdo a la distribución $\{p_{x} \}$ y la probabilidad que el evento $S$ ocurra de acuerdo a la distribución $\{q_{x} \}$. Se puede decir que el evento $S$ es el evento óptimo para examinar las diferencias entre $\{p_{x} \}$ y $\{q_{x} \}$.
\\
Pasando a un contexto cuántico, la distancia de traza entre dos estados cuánticos $\rho$ y $\sigma$ es,
\begin{equation}
D(\rho,\sigma) \equiv \frac{1}{2} \Tr |\rho-\sigma|.	
\end{equation}
\\
donde $|M| \equiv \sqrt{M^{\dagger}M}$ con la raíz positiva. Esta definición generaliza la distancia de traza clásica, si $\rho$ y $\sigma$ conmutan, son diagonales en una misma base, luego
\begin{align*}
D(\rho,\sigma) &= \frac{1}{2} \Tr |\sum_{i} (r_{i}-s_{i})\ket{i}\bra{i}|\\
\quad &= D(r_{i},s_{i}),
\end{align*}
donde $r_{i}$ y $s_{i}$ son los elementos diagonales de $\rho$ y $\sigma$ respectivamente. Al igual que con la distancia de traza clásica, es posible dar un sentido más físico a esta definición. El siguiente teorema construirá la conexión \cite{NielsenInformation}.
\begin{theorem}
Sea $\{ E_{m}\}$ un POVM, con  $p_{m} \equiv \Tr(\rho E_{m})$  y  $q_{m}\equiv \Tr(\sigma E_{m})$ como las probabilidades de obtener un resultado de una medida $m$. Luego

\begin{equation}
D(\rho,\sigma)= \max_{ \{ E_{m}\} } D(p_{m},q_{m}),
\end{equation}
donde la maximización es sobre todos los POVMs $\{ E_{m}\}$.
\end{theorem}

\begin{proof}

Véase que 

\begin{equation}
D(p_{m},q_{m})= \frac{1}{2} \sum_{m} \Big|\Tr(E_{m}(\rho- \sigma)) \Big|.
\end{equation}
Usando la descomposición espectral se tiene que $\rho- \sigma=Q-S$, donde $Q$ y $S$ son operadores positivos con soporte ortogonal. Luego $|\rho - \sigma|= Q+S$, y
\begin{align}
\big|\Tr(E_{m}(\rho- \sigma)) \big| &= \big|\Tr(E_{m}(Q-S)) \big| \\
\quad &\leq \Tr(E_{m}(Q+S))\\
\quad &\leq \Tr(E_{m}|\rho -\sigma|).
\end{align}
Luego 

\begin{align}
D(p_{m},q_{m}) &\leq \frac{1}{2} \sum_{m} \Tr(E_{m}|\rho-\sigma|)\\
\quad &= \frac{1}{2} \Tr(|\rho -\sigma|)\\
\quad &= D(\rho,\sigma),
\end{align}
se usó la relación de completitud de los elementos de POVM. Por otro lado, si se escogen medidas donde los elementos POVM incluyen proyectores sobre el soporte de $Q$ y $S$, se ve que existen mediciones que dan distribuciones de probabilidad tales que $D(p_{m},q_{m})= D(\rho,\sigma)$.

\end{proof}
Entonces se puede decir que si dos operadores de densidad son cercanos, según la distancia de traza, cualquier medición hecha en este estado cuántico dará dos distribuciones de probabilidad que estarán cercanas, en el sentido clásico de la distancia de traza. También se puede ver cómo el límite superior a la distancia de traza cuántica es igual a la distancia de traza clásica.
\\
La distancia de traza es la forma en la que se da un sentido de lejanía entre estados cuánticos. Es una herramienta que permitirá decir qué tan lejos está un estado de ser un estado canónico, punto fundamental en el artículo de Popescu \textit{et al} para especificar que casi todos los estados son cercanos al estado canónico. Ya con las herramientas en su lugar, en la siguiente sección se prosigue a plantear la situación de interés.

\section{Definiciones}

Como lo que se estudiará es un sistema cuántico aislado compuesto por subsistema y ambiente es preciso la notación que se usará a lo largo de este capítulo y el siguiente, para no tener ambigüedades. Entonces, se tomará una pausa,en esta sección, para dejar la notación clara.
\\
Se tiene un sistema cuántico grande descrito por un espacio de Hilbert $\mathcal{H}$ al que se llamará el universo. El universo puede ser dividido en dos subsistemas. El primero se llamará el sistema $S$ y al segundo se le dará el nombre de ambiente $E$, y se supone que la dimensión del ambiente es mucho mayor que la del sistema \footnote{En ocasiones a $S$ se le dirá subsistema y $E$ se le podrá llamar baño. Estos nombres son equivalentes a los anteriores}. Se descompone $\mathcal{H}$ como $\mathcal{H}=\mathcal{H}_{S} \otimes \mathcal{H}_{E}$, con dimensiones $d_{S}$ y $d_{E}$ respectivamente. Si al universo se le pone una restricción global, el espacio de Hilbert en el que se encuentra sería $\mathcal{H}_{R} \subseteq \mathcal{H}$.
\\
Para evitar espacios de dimensión infinita se introduce un tope para altas energías y así se mantiene la dimensión finita. Además, se eliminan términos de interacción del Hamiltoniano que lo lleven a subespacios no permitidos.  No se ha especificado nada sobre el subsistema o el ambiente (excepto las proporciones de sus dimensiones). Esto permite decir que cualquier descomposición del espacio de Hilbert especifica un subsistema y un baño. El subsistema $S$ puede ser cualquier cosa: desde una partícula hasta el conjunto de partículas distribuidas por todo el baño.
\\
El estado global puro del universo se escribirá como $\ket{\phi(t)}$ en un tiempo $t$ y su matriz de densidad se escribirá $\rho(t)=\ket{\phi(t)}\bra{\phi(t)}$. El estado del subsistema se encontrará al hacer una traza parcial del ambiente sobre el estado del universo $\rho_{S}= \Tr _{B} \rho(t)$; similarmente, el estado del ambiente está dado por $\rho_{B}=\Tr _{S} \rho(t)$ \cite{WildeInformation}. 
\\
El promedio temporal del universo es:
\begin{equation}
\omega= \langle \rho(t) \rangle_{t}= \lim_{\tau \to \infty} \frac{1}{\tau} \int_{0}^{\tau} \rho (t)dt
\end{equation}
de manera análoga $\omega_{S}$ y $\omega_{B}$ son el promedio temporal para el sistema y el ambiente respectivamente \cite{TodaStat}. También se tiene el promedio $\langle \cdot \rangle_{\phi}$ que es sobre todos los estados $\ket{\phi} \in \mathcal{H}_{R}$ de acuerdo a la medida estándar (unitariamente invariante). Esta medida se usa para hallar volúmenes de conjuntos de estados.
\\
Esta notación se usará de aquí en adelante. Es una notación usada generalmente por la literatura pero hay detalles que es mejor especificar.
\section{Idea Conceptual}
En esta parte se dará la idea central del artículo de Popescu \textit{et al}. Para empezar este nuevo tratamiento de los fundamentos de la mecánica estadística, se supone que se tiene un sistema cuántico aislado: el universo. Se sepaa el universo en dos subsistemas, el subsistema y el ambiente, y dando como condición que el ambiente sea más grande que el subsistema. Este universo está descrito por un estado cuántico puro que obedece una restricción global, arbitraria por el momento. Se plantea que el sistema alcanza el equilibrio térmico por medio de la interacción mutua a consecuencia del entrelazamiento del sistema y el ambiente  \cite{Popescu2006}. Lo que se presentará más adelante es una definición más rigurosa que ayudará a dar cotas para la expresión ``el ambiente es más grande".
\\
Esta idea permite formular un principio canónico general: el sistema estará termalizado para casi todos los estados puros del universo. Esto está soportado por límites cuantitativos. La restricción que se impone no es una restricción específica, esto generaliza los resultados tradicionales dados en la literatura donde se toma por restricción la energía \cite{KardarStat}.
\\
Ya poniendo lo dicho en un contexto un poco más matemático y siguiendo a Popescu \textit{et al}, el universo aislado y bastante grande tiene dos partes: el sistema $S$ y el ambiente $E$. La dimensión del ambiente es mucho más grande que la del sistema. Además se le impone una restricción global al universo llamada $R$. Desde la mecánica cuántica esto puede ponerse como restricciones en el espacio de Hilbert, restricción de los estados posibles:

\begin{equation}
\mathcal{H}_{R}\subseteq \mathcal{H}_{S}\otimes \mathcal{H}_{E},
\end{equation}
\\
donde $\mathcal{H}_{S}$ y $\mathcal{H}_{E}$ son los espacios de Hilbert del sistema y el ambiente con dimension $d_{S}$  y $d_{E}$ respectivamente. Es bueno recalcar que $R$ es una restricción arbitraria generalmente tomada como la energía del universo en la mecánica estadística. Ahora se define el estado equiprobable del universo bajo $R$ como:

\begin{equation}
\mathcal{E}_{R} = \frac{1}{d_{R}} \mathbbm{1}_{R},
\end{equation}

Donde $\mathbbm{1}_{R}$ es el operador identidad (proyección) sobre el espacio de Hilbert  $\mathcal{H}_{R}$  que tiene dimensión $d_{R}$. Esto se relaciona con el principio de probabilidades iguales porque este es el estado máximamente mezclado en $\mathcal{H}_{R}$  \cite{SakuraiQuantum}. Por ser así, todos los estados bajo la restricción de $R$ tienen la misma probabilidad de ser el estado en el que se encuentre el sistema.
\\
Definimos $\Omega_{S}$ como el estado canónico que está restringido por $R$ cuando el universo se encuentra en el estado $\mathcal{E}_{R}$. Esto significa que, si se hace una traza parcial del ambiente al universo, se obtiene un estado definido como el estado canónico:

\begin{equation}
 \Omega_{S} =\Tr_{E} \mathcal{E}_{R}.
\end{equation}
\\
Para lo que sigue a continuación se hace un supuesto importante, y es que el universo está en un estado puro $\ket{\phi}$ y no en un estado mixto $\mathcal{E}_{R}$. Esto quiere decir que se conoce todo lo que es permitido por la mecánica cuántica del universo. Si estuviese en un estado mixto significaría que nosotros no tenemos toda la información posible \cite{SakuraiQuantum}. Ahora lo que se quiere ver es que, pese a que el estado del universo es puro, el estado reducido del sistema

\begin{equation}
\rho_{S}=\Tr_{E}\ket{\phi}\bra{\phi},
\end{equation}

se acerca al estado canónico para la gran mayoría de los casos; es decir:

\begin{equation}
\rho_{S} \approx \Omega_{S}.
\end{equation}
\\
Por consiguiente, para casi todos los estados puros del universo $\ket{\phi} \in \mathcal{H}_{R}$, el sistema se comporta como si el universo estuviese en el estado mixto equiprobable $\mathcal{E}_{R}$. Este es el principio general canónico. Clarificando lo esbozado, el estado canónico del sistema $\Omega_{S}$ es el estado del sistema cuando el universo se encuentra en el estado equiprobable $\mathcal{E}_{R}$. Se puede interpretar el principio general canónico como un principio que estipula que las probabilidades iguales del sistema son aparentes porque para casi cualquier estado del universo, que sea puro, un subsistema de este universo que cumpla con ser lo suficientemente pequeño se comporta como si el universo estuviese en el estado equiprobable $\mathcal{E}_{R}$. Cabe recordar que aún no se ha especificado la restricción $R$, luego todo este análisis es general. La restricción no necesariamente debe ser la energía u otras cantidades que se conserven. Esto hace que $\Omega_{S}$ no  deba ser obligatoriamente el estado canónico usual; puede ser el gran canónico o cualquier otro que sea acorde con la restricción impuesta\cite{ReichlStat}. Este principio puede ser de utilidad cuando la interacción entre el ambiente y el sistema no es débil o cuando las interacciones son complicadas.

\section{Formulación Matemática}

Hasta ahora no se han entrado en los detalles ni en qué significan los términos bastante pequeño y bastante grande, ni tampoco se ha demostrado el principio general canónico. En esta sección se replicarán los detalles matemáticos, se mostrarán las herramientas usadas y la demostración de los teoremas que Popescu \textit{et al} siguieron. En la siguiente sección se dará una perspectiva más física a lo hecho aquí.
\\
Para empezar se debe decir cuál será la distancia que usaremos para darle un sentido de cercanía a los estados $\rho_{S}$ y $\Omega_{S}$. La distancia a usar es bastante conocida en la teoría cuántica de la información, la distancia de traza \cite{NielsenInformation}. Esta se define como:
\begin{equation}
D(\rho_{S}, \Omega_{S})= \frac{1}{2} \Tr |\rho_{S} -\Omega_{S}|=\frac{1}{2} \Tr \sqrt{(\rho_{S} -\Omega_{S})^{\dag}(\rho_{S} -\Omega_{S})}.
\end{equation}

Esta distancia de traza se relaciona con la distancia de norma de manera sencilla

\begin{equation}
\norm{\rho_{S}-\Omega_{S}}_{1}=2 D(\rho_{S}, \Omega_{S}).
\end{equation}

Teniendo ya una forma de darle sentido al concepto de que dos estados son cercanos entonces se puede plantear el teorema central de \cite{Popescu2006}:
\\
\begin{theorem} \label{teorema principal}
Para un estado escogido de manera aleatoria $\ket{\phi} \in \mathcal{H}_{R} \subseteq \mathcal{H}_{S} \otimes \mathcal{H}_{E} $ y un $\epsilon > 0$ arbitrario, la distancia entre la matriz densidad reducida del sistema $\rho_{S}=\Tr_{E}(\ket{\phi} \bra{\phi})$  y el estado canónico $\Omega_{S}=\Tr_{E} ( \mathcal{E}_{R})$ está dada probabilísticamente por 

\begin{equation}
Pr_{\phi} \{  \norm{\rho_{S} -\Omega_{S}}_{1} \geq \eta \} \leq \eta',
\end{equation}

Donde 

\begin{equation}
\eta= \epsilon + \sqrt{ \frac{d_{S}}{d_{E}^{eff}} },
\end{equation}

\begin{equation}
\eta'=2\exp (-C d_{R} \epsilon^{2} ).
\end{equation}

y las constantes son: $ C=(18 \pi^{3})^{-1}, d_{R} = \dim \mathcal{H}_{R}, d_{S} = \dim \mathcal{H}_{S} $. $d_{E}^{eff}$ es la medida efectiva del tamaño del ambiente,
\begin{equation}
d_{E}^{eff}= \frac{1}{\Tr \Omega_{E}^{2}} \ge \frac{d_{R}}{d_{S}},
\end{equation}
\\
donde $\Omega_{E}= \Tr_{S} \mathcal{E}_{R}$.\\
\end{theorem}

Ambas cantidades $\eta $ y $\eta'$ serán pequeñas. Esto implica que el estado estará cercano al estado canónico con alta probabilidad cuando la dimensión efectiva del ambiente sea mucho más grande que la del sistema (es decir $d_{E}^{eff} >> d_{S}$) y  $d_{R}\epsilon^2>>1>>\epsilon$. Esta última condición se puede asegurar cuando el espacio accesible total es grande (es decir $d_{R}>>1$), escogiendo $\epsilon=d_{R}^{-\frac{1}{3}}$.\\
Esta es la formulación matemática de la perspectiva de Popescu \textit{et al}. El teorema anterior dice que la probabilidad de encontrar estados del subsistema que sean lejanos del estado canónico decae de manera exponencial con el tamaño del sistema. Por lo tanto el teorema formaliza lo que significa que el ambiente deba ser muy grande. Además permite decir con seguridad que los estados que están lejanos del canónico son extremadamente raros de encontrar, no son genéricos.
\\

\subsection{Lema de Levy} \label{ levy}
Para poder demostrar el teorema \ref{teorema principal} se puede hacer de dos formas \cite{Popescu2006}, pero se seguirá la que usa el lema de Levy. Este lema dice: sea $f$ una función definida en la hiperesfera. Al seleccionar un punto $\phi$ aleatoriamente de una hiperesfera de dimensión alta, y que $f(\phi)$ no cambie muy rápido, entonces $f(\phi) \approx \langle f \rangle $ con alta probabilidad, más exactamente  \cite{Lema}:
\\
\begin{lemma} \label{lemma de levy}

Dada una función $f: \mathbb{S}^d \to \mathbb{R} $ definida en la hiperesfera d-dimensional $\mathbb{S}^d$ , y un punto $\phi \in \mathbb{S}^d $ es escogido de manera uniformemente aleatoria,
\begin{equation}
Pr_{\phi} \{ |f(\phi)- \langle f \rangle| \geq \epsilon \} \leq 2 \exp(-\frac{2C(d+1)\epsilon^2}{\eta^2})
\end{equation}
donde $\eta$ es la constante de Lipschitz de $f$, dada por $\eta= \sup|\nabla f|$ y $C=(18 \pi^3)^{-1} $.\\

\end{lemma}

Los conceptos manejados por el teorema \ref{lemma de levy} son conocidos generalmente a excepción de la llamada constante de Lipschitz. Para poder entender qué es la  constante de Lipschitz se debe ver primero qué significa que una función sea Lipschitz continua. 
\\
La definición de continuidad dada en el cálculo básico es:

\theoremstyle{definition}
\begin{definition}{continuidad}
Sea $f: I \to \mathbb{R}$ donde $I$ puede ser un intervalo abierto $(a,b)$ o uno cerrado $[a,b]$, además $C \in I$. Se dice que $f$ es continua en $C$ si y solo si para todo $ \epsilon >0 $  existe un $ \delta >0 $ tal que si $ |x-c| < \delta \longrightarrow |f(x)-f(c)|< \epsilon $.
\end{definition} 

La  definición anterior es la usada por lo general, pero hay sutilezas en este concepto que no siempre son mostradas; como por ejemplo que $\delta$ depende de donde se ponga el punto $C$. Esto se ve claramente en la siguiente función: $f: (0,1) \to \mathbb{R}$, $f(x)=\frac{1}{x} $, al $C$ estar más lejos del $0$ permite un $\delta$ más grande pero al acercarse al $0$ el $\delta$ debe ser más pequeño. La continuidad de Lipschitz permite que se defina un $\delta$ constante sin importar dónde se encuentra el $C$. Para resolver este detalle se motiva la definicón de Lipschitz continuo. Se es Lipschitz continuo con constante $\eta$ si

\begin{equation}
|f(x) -f(y)| \leq \eta |x-y|,
\end{equation}

esto permite decir que  $|f(x)-f(y)| < \epsilon $ entonces $\delta < \frac{\epsilon}{\eta} $. Ahora si f es derivable y $\nabla f$ es acotado, para $x$, $y$ $ \in R$ existe $\xi$ que se encuentre dentro del intervalo $(x,y)$; tal que:


\begin{align}
&\implies f(x)-f(y) = \nabla f(\xi) (x-y) \\
&\implies |f(x)- f(y)| \le |\nabla f(\xi)| |x-y| \\
&\implies |f(x)- f(y)| 	\le \sup|\nabla f(\xi)| |x-y|,
\end{align}

como $\nabla f$ es acotado se tiene que $\sup |\nabla f(\xi)|=\eta$.\\

Gracias a la normalización, los estados puros en $\mathcal{H}_{R}$ se pueden representar como puntos sobre la superficie de una hiperesfera de dimensión $2d_{R}-1$, o sea  $\mathbb{S}^{2d_{R}-1}$ \cite{SakuraiQuantum}. Luego, se puede aplicar \ref{lemma de levy} a estado cuánticos $\phi$ aleatoriamente seleccionados. Para los estados seleccionados aleatoriamente $\phi \in \mathcal{H}_{R}$, se desea mostrar que $\norm{\rho_{S}- \Omega_{S}}_{1} \approx 0$ con alta probabilidad. Para poder usar \ref{lemma de levy} primero  debe encontrarse la constante de Lipschitz. Ya teniendo una idea de qué es ser Lipschitz continuo, se encontrará una cota para la constante $\eta$ de la función $f(\phi)=\norm{\rho_{S}-\Omega_{S}}_{1}$, que es la función que nos interesa para el problema físico. Para lograr esto se procederá de la siguiente forma: se definen dos estados reducidos $\rho_{1}= \Tr_{E} (\ket{\phi_{1}} \bra{\phi_{1}})$ y $\rho_{2}= \Tr_{E}(\ket{\phi_{2}} \bra{\phi_{2}})$, entonces

\begin{equation}
|f(\phi_{1})-f(\phi_{2})|^2= |\norm{\rho_{1}-\Omega}_{1} - \norm{\rho_{2}-\Omega}_{1}|^2.
\end{equation}

como $\norm{M}_{1}$ es una distancia (esto es $d(\rho_{1},\Omega)= \norm{\rho_{1}-\Omega}_{1}$) es cierto para un espacio métrico que

\begin{equation}
|d(x,z)-d(y,z)| \le d(x,y),
\end{equation}

Por lo tanto 

\begin{equation}
\Big | \norm{\rho_{1}-\Omega}_{1} - \norm{\rho_{2}-\Omega}_{1} \Big |^2 \le \norm{\rho_{1}- \rho_{2} }_{1}^2= \norm{\Tr_{E}(\ket{\phi_{1}} \bra{\phi_{1}}-\ket{\phi_{2}} \bra{\phi_{2}})}_{1}^{2}.
\end{equation}

Como existe una cota a la norma de una traza parcial dada por

\begin{equation}
\norm{\Tr_{\mathcal{B}}(M)}_{p} \le [dim(\mathcal{H_{B}})]^{\frac{p-1}{p}} \norm{M}_{p},
\end{equation}

entones la cota sobre los estados reducidos queda 
\begin{equation}
\norm{\Tr_{E}(\ket{\phi_{1}} \bra{\phi_{1}}-\ket{\phi_{2}} \bra{\phi_{2}})}_{1} \le \norm{\ket{\phi_{1}} \bra{\phi_{1}}-\ket{\phi_{2}} \bra{\phi_{2}}}_{1}.
\end{equation}

Por lo tanto se tiene hasta ahora:
\begin{equation}
\norm{\rho_{1}- \rho_{2} }_{1}^2 \le \norm{\ket{\phi_{1}} \bra{\phi_{1}}-\ket{\phi_{2}} \bra{\phi_{2}}}_{1}^{2},
\end{equation}

Usando la hermiticidad de $\rho$ y el teorema espectral se puede descomponer $\rho= UDU^{\dag}$ donde $U$ es un operador unitario y $D$ es diagonal. Junto con las propiedades de la traza $\Tr(\sqrt{UD^2U^{\dag}})= Tr(U\sqrt{D^2}U^{\dag})= \Tr(\sqrt{D^{2}})$ se llega a que
\begin{equation}
\norm{\ket{\phi_{1}} \bra{\phi_{1}}-\ket{\phi_{2}} \bra{\phi_{2}}}_{1}^{2} = 4(1-|\bra{\phi_{1}} \ket{\phi_{2}}|^{2});
\end{equation}
entonces,
\begin{equation}
 4(1-|\bra{\phi_{1}} \ket{\phi_{2}}|^{2}) \le 4|\ket{\phi_{1}}-\ket{\phi_{2}}|^2.
\end{equation}

Uniendo todos los pasos anteriores
\begin{equation}
|f(\phi_{1})-f(\phi_{2})|^{2} \le  4|\ket{\phi}-\ket{\phi}|^2
\end{equation}

o sea 
\begin{equation}
|f(\phi_{1})-f(\phi_{2})| \le  2|\ket{\phi}-\ket{\phi}|,
\end{equation}

Con esto se muestra que $\eta \le 2$.
\\
Visto que el lema de Levy se puede usar para estados cuánticos, el trabajo más pesado ya sido hecho por este lema. Ahora se debe acoplar con la idea del principio general canónico, lo cual se seguirá haciendo en la próxima subsección.

\subsection{Demonstración del Principio General Canónico}
En esta parte se dará una demostración matemática explícita del principio general canónico usando el lema de Levy. Se entrará en los detalles matemáticos de este lema y las cotas adicionales que se necesitan para poder llegar al teorema \ref{teorema principal}. Habiendo dado una cota para $\eta$, se puede usar por completo el lema \ref{lemma de levy} para la función $f(\phi)=\norm{\rho_{S} -\Omega_{S}}_{1}$ recordando que se reemplazará $d$ en el lema por $d=2d_{R}-1$.Tomando la parte derecha de la desigualdad de \ref{lemma de levy}  y sustituyendo la dimensión, se tiene:

\begin{equation}
 2 \exp(-\frac{2C(d+1)\epsilon^2}{\eta^2})= 2 \exp(-\frac{4Cd_{R}\epsilon^2}{\eta^2}).
\end{equation}

Como $\eta \le 2$, entonces

\begin{equation} \label{desigualdad}
2\exp(-Cd_{R}\epsilon^2) \ge 2 \exp(-\frac{4Cd_{R}\epsilon^2}{\eta^2}) \ge \Pr_{\phi}[|f(\phi)- \langle f \rangle| \ge \epsilon ].
\end{equation}

Mirando más atentamente  $|f(\phi)- \langle f \rangle| \ge \epsilon $, como la norma de traza es una distancia, se tiene que  $\norm{\rho_{S} -\Omega_{S}}_{1} \ge 0$, entonces


\begin{equation}
\norm{\rho_{S} -\Omega_{S}}_{1}- \langle \norm{\rho_{S} -\Omega_{S}}_{1} \rangle_{\phi} \ge \epsilon.
\end{equation}

Definiendo a $\mu = \epsilon + \langle \norm{\rho_{S} -\Omega_{S}}_{1} \rangle_{\phi} $ y $\mu'=2 \exp(-Cd_{R}\epsilon^2)$, esto permite organizar el lema de Levy así:

\begin{equation} \label{eq.3}
\Pr_{\phi}[\norm{\rho_{S} -\Omega_{S}}_{1} \ge \mu] \le \mu'.
\end{equation}

Debido a que $d_{R}>>1$, se asegura que $\epsilon$ y $\mu'$ son cantidades pequeñas al escoger $\epsilon=d_{R}^{-1/3}$. Para llegar a \ref{teorema principal} falta acotar $\mu$ con las dimensiones de los espacios conocidos. Se impondrá una cota a $\langle \norm{\rho_{S} -\Omega_{S}}_{1} \rangle_{\phi}$; lo primero  para lograr esta empresa es acotar este promedio con trazas del estado del sistema  y luego se calcularán estas trazas para poder dejar la cota en términos de las dimensiones del sistema y la dimensión efectiva del ambiente. Se procede a encontrar la relación entre $\norm{\rho_{S} -\Omega_{S}}_{1}$ y $\norm{\rho_{S} -\Omega_{S}}_{2}$. Esto se hará por facilidad de manejo, ya que la norma de Hilbert-Schmidt ($\norm{.}_{2}$) es más sencilla para trabajar que la norma de traza, y luego se procederá con lo planeado.
\\
La relación entre estas dos normas se puede ver desde el manejo de matrices. Sea $M$ una matriz $n \times n$ se sabe que si $M$ tiene $\lambda_{i}$ valores propios entonces:
\begin{equation}
\Tr M= \sum_{i} \lambda_{i}
\end{equation}
con esto se puede escribir de manera explícita la norma de traza 
\begin{equation}
\norm{M}_{1}^2=(\Tr|M|)^{2}=n^{2} \Big( \frac{1}{n}\sum_{i} |\lambda_{i}| \Big)^{2}.
\end{equation}
Como la función $x^{2}$ es convexa se puede usar la desigualdad de Jensen que dice: sean $a_{1},a_{2},...,a_{n} \le 0$ constantes y $a_{1} +...+a_{n}=1$ sea $f: I \to \mathbb{R}$ donde I es un intervalo, $x_{1},...,x_{n} \in I$ entonces
\begin{equation}
f(a_{1}x_{1}+...+a_{n}x_{n}) \le a_{1}f(x_{1})+...+a_{n}f(x_{n}),
\end{equation}

con esto se puede decir que

\begin{equation}
\Big( \frac{1}{n}\sum_{i} |\lambda_{i}| \Big)^{2} \le \frac{1}{n}\sum_{i} |\lambda_{i}|^{2}.
\end{equation}
Pero se sabe que 
\begin{equation}
\sum_{i} |\lambda_{i}|^2= \Tr(|M|^2)=\norm{M}_{2}^{2}
\end{equation}
se llega entonces a la conclusión que 
\begin{equation}
\norm{M}_{1}^{2} = n^{2}\Bigg( \frac{1}{n} \sum_{i}| \lambda_{i} | \Bigg)^{2} \le  n^{2} \frac{1}{n} \sum_{i} | \lambda_{i} |^{2}= n\norm{M}_{2}^{2}
\end{equation}
Gracias a lo anterior la relación entre normas es:
\begin{equation}\label{eq:0}
\norm{\rho_{S} - \Omega_{S}}_{1} \le \sqrt{d_{S}}\norm{\rho_{S} - \Omega_{S}}_{2}
\end{equation}
Esta relación se usará un poco más adelante.\\

Volviendo al cálculo de $\langle \norm{\rho_{S} -\Omega_{S}}_{1} \rangle_{\phi}$ se acotará la norma de Hilbert-Schmidt, y con la relación entre normas se dará la desigualdad que limite el promedio de la norma de traza. Para empezar se recuerda que $ \langle f^{2} \rangle-\langle f \rangle^{2} \ge 0$ donde $\langle f \rangle = \int_{\mathcal{M}} f(x)p(x)dx$. Tomando a $f$ como $f= \norm{\rho_{S}-\Omega_{S}}_{2}$ entonces 

\begin{equation}
\langle \norm{ \rho_{S}-\Omega_{S} }_{2} \rangle \le \sqrt{ \langle \norm{ \rho_{S}-\Omega_{S} }_{2}^{2}\rangle}.
\end{equation}

Acordándose que este promedio es tomado con los estados $\ket{\phi}$, se omitirá por ahora el subíndice indicando este promedio; esto hace que $\Omega_{S}$ se tome constante. Por hermiticidad de $\rho_{S}-\Omega_{S}$ 

\begin{equation}
\sqrt{\langle \norm{ \rho_{S}-\Omega_{S} }_{2}^{2}\rangle} = \sqrt{\langle \Tr(\rho_{S}-\Omega_{S})^{2} \rangle}
\end{equation}

\begin{equation}
\sqrt{\langle \Tr( \rho_{S}-\Omega_{S})^{2} \rangle}= \sqrt{\langle \Tr(\rho_{S})^{2}\rangle -2 \Tr(\langle \rho_{S} \rangle \Omega_{S})+ \Tr(\Omega_{S}^{2}) }
\end{equation}

porque $\langle \rho_{S} \rangle=\Omega_{S}$. Luego se llega a

\begin{equation}
\langle \norm{ \rho_{S}-\Omega_{S} }_{2}\rangle \le \sqrt{\langle \norm{ \rho_{S}-\Omega_{S} }_{2}^{2}\rangle}= \sqrt{\langle \Tr(\rho_{S})^{2}\rangle - \Tr(\Omega_{S}^{2}) }.
\end{equation}

Por la relación entre la norma de traza y la norma de Hilbert-Schmidt, se concluye lo que se quería; es decir,

\begin{equation}
\langle \norm{ \rho_{S}-\Omega_{S} }_{1}\rangle \le \sqrt{d_{S}( \langle \Tr(\rho_{S})^{2}\rangle -\Tr(\Omega_{S}^{2}) ) }.
\end{equation}
\\
Aunque ya se ha acotado $\langle \norm{ \rho_{S}-\Omega_{S} }_{1}\rangle$ se quiere relacionar esta cota con las dimensiones del sistema. Para esto se procederá a demostrar la desigualdad
\begin{equation}
\langle \Tr \rho_{S}^{2} \rangle \le \Tr \langle \rho_{S} \rangle^{2} +\Tr \langle \rho_E \rangle^{2},
\end{equation}
recordando que el promedio es tomado con respecto a los estados $\ket{\phi}$; los métodos usados para encontrar esta desigualdad son usados también en destilación de entrelazamiento aleatorio y codificación de canal cuántico aleatorio \cite{QuantumDistilation}. Para poder hacer este cálculo se introduce una segunda copia del espacio de Hilbert. Ahora el problema se trabaja en $\mathcal{H}_{R} \otimes \mathcal{H}_{R'}$, donde $\mathcal{H}_{R'} \subseteq \mathcal{H}_{S'} \otimes \mathcal{H}_{E'}$, donde $\mathcal{H}_{S'}$ y $\mathcal{H}_{E'}$ son los espacios de la copia del subsistema y el ambiente respectivamente. Percatándose de lo siguiente

\begin{equation}
\Tr_{S} (\rho_{S})^2 = \sum_{k} (\rho_{kk})^{2} = \sum_{k,l,k',l'}(\rho_{kl})(\rho_{k'l'}) \bra{kk'}\ket{ll'}\bra{l'l'}\ket{kk'}.
\end{equation}

Sea $F_{SS'}$ la operación "flip" $S \longleftrightarrow S'$ definida de esta manera:

\begin{equation}
F_{SS'} =\sum_{S,S'} \ket{s'}\bra{s}_{S} \otimes \ket{s}\bra{s'}_{S'}
\end{equation}

Entonces

\begin{align*} 
\sum_{k,l,k',l'}(\rho_{kl})(\rho_{k'l'}) \bra{kk'}\ket{ll'}\bra{l'l'}\ket{kk'} &= \Tr_{SS'} ((\rho_{S} \otimes \rho_{S'})F_{SS'})\\
\quad &=\Tr_{RR'}((\ket{\phi} \bra{\phi} \otimes \ket{\phi} \bra{\phi})_{RR'}(F_{SS'} \otimes \mathbbm{1}_{EE'}))
\end{align*}



Pero como se quiere $\langle \Tr (\rho)^{2} \rangle= \int \Tr (\rho)^{2} d\phi $. Entonces para resolver esto se requiere saber $V=\int (\ket{\phi} \bra{\phi} \otimes \ket{\phi} \bra{\phi})d\phi$. V puede representarse como:

\begin{equation}
V= \alpha \Pi_{RR'}^{sim} + \beta \Pi_{RR'}^{anti},
\end{equation}
$\alpha$ y $\beta$ son constantes y $\Pi_{RR'}^{sim/anti}$ son proyectores en el subespacio simétrico y antisimétrico de $\mathcal{H_{R} \otimes H_{R'}}$ respectivamente, esto es posible por la invarianza unitaria de V. Debido a que 	
\begin{equation}
(\ket{\phi} \bra{\phi} \otimes \ket{\phi} \bra{\phi})\frac{1}{\sqrt{2}} ( \ket{ab} -\ket{ba})=0  \quad  \forall a,b,\phi
\end{equation}
la parte antisimétrica siempre debe ser 0 entonces $\beta=0$. Por la normalización de $V$ se llega a $\alpha= \frac{1}{dim(RR'_{sim})}$, la dimensión del espacio $RR'_{sim}$ está dada por el álgebra lineal $dim(RR'_{sim})= \frac{d_{R}(d_{R}+1)}{2}$.Entonces
\begin{equation}
V= \langle \ket{\phi} \bra{\phi} \otimes \ket{\phi} \bra{\phi} \rangle = \frac{2}{d_{R}(d_{R} +1)} \Pi_{RR'}^{sim}.
\end{equation}
Luego se tiene que 
\begin{equation}
\langle \Tr (\rho)^{2} \rangle = \Tr_{RR'} \Big( \Big( \frac{2}{d_{R}(d_{R} +1)} \Pi_{RR'}^{sim} \Big)(F_{SS'} \otimes \mathbbm{1}_{EE'}) \Big).
\end{equation}
Al ser $\Pi_{RR'}^{sim}$ un proyector simétrico se escribe
\begin{equation}
\Pi_{RR'}^{sim}=\frac{1}{2}(\mathbbm{1}_{RR'}+(F_{RR'} )),
\end{equation}
donde $F_{RR'}$ es el operador "flip"  $R \longleftrightarrow R'$. Como $F_{RR'}$ es un operador que actúa sobre $RR'$ puede escribirse como $F_{RR'}= \mathbbm{1}_{RR'}(F_{SS'} \otimes F_{EE'})$. Reuniendo todo lo anterior

\begin{equation}
\langle \Tr_{S} \rho_{S}^2 \rangle = \Tr_{RR'} \Bigg( \frac{1}{d_{R}(d_{R}+1)} \Big( \mathbbm{1}_{RR'}+\mathbbm{1}_{RR'}(F_{SS'} \otimes F_{EE'}) \Big)  (F_{SS'}\otimes \mathbbm{1}_{EE'})   \Bigg)
\end{equation}

Distribuyendo y sabiendo que al hacer dos veces la operación ``flip" no afecta nada se sigue que

\begin{equation}
\Tr_{RR'} \Bigg( \frac{\mathbbm{1}_{RR'}}{d_{R}(d_{R}+1)} F_{SS'} \otimes \mathbbm{1}_{EE'} + \frac{\mathbbm{1}_{RR'}}{d_{R}(d_{R}+1)} (\mathbbm{1}_{SS'} \otimes F_{EE'})  \Bigg).
\end{equation}

Por las propiedades aditivas de la traza junto con $\mathbbm{1}_{R} \otimes \mathbbm{1}_{R'}$  y $\frac{1}{d_{R}(d_{R}+1)} \le \frac{1}{d_{R}^{2}}$ se llega a que

\begin{align*}
\langle \Tr_{S} \rho_{S}^2 \rangle &= \Tr_{RR'} \Bigg( \Bigg( \frac{\mathbbm{1}_{RR'}}{d_{R}(d_{R}+1)} \Bigg) (F_{SS'} \otimes \mathbbm{1}_{EE'})  \Bigg) \\
\qquad  &+ \Tr_{RR'} \Bigg( \Bigg( \frac{\mathbbm{1}_{RR'}}{d_{R}(d_{R}+1)} \Bigg) (\mathbbm{1}_{SS'} \otimes F_{EE'} )  \Bigg)\\ 
&\leq \Tr_{RR'} \Bigg( \Bigg( \frac{\mathbbm{1}_{R}}{d_{R}} \otimes  \frac{\mathbbm{1}_{R'}}{d_{R}}  \Bigg) (F_{SS'} \otimes \mathbbm{1}_{EE'})  \Bigg)\\
\qquad &+ \Tr_{RR'} \Bigg( \Bigg( \frac{\mathbbm{1}_{R}}{d_{R}} \otimes  \frac{\mathbbm{1}_{R'}}{d_{R}}  \Bigg) (\mathbbm{1}_{SS'} \otimes F_{EE'} )  \Bigg)
\end{align*}
	
Recordando que $\frac{\mathbbm{1}_{R}}{d_{R}}= \mathcal{E}_{R}$ y $\Omega_{S}=\Tr_{E}(\mathcal{E}_{R})$ se tiene que:

\begin{align*}
\Tr_{RR'}\Bigg(\frac{\mathbbm{1}_{R}}{d_{R}} \otimes \frac{\mathbbm{1}_{R'}}{d_{R}} (F_{SS'} \otimes 		\mathbbm{1}_{EE'}) \Bigg) &+ \Tr_{RR'}\Bigg(\frac{\mathbbm{1}_{R}}{d_{R}} \otimes \frac{\mathbbm{1}_{R'}}{d_{R}} (\mathbbm{1}_{SS'}\otimes 	F_{EE'}) \Bigg) \notag \\
&= \Tr_{SS'}((\Omega_{S} \otimes \Omega_{S})F_{SS'}) + \Tr_{EE'}((\Omega_{E} \otimes \Omega_{E})F_{EE'}).
\end{align*}
Entonces se llega a lo que se quería:	
\begin{equation}
\langle \Tr_{S} \rho_{S}^{2} \rangle \le \Tr_{S} \Omega_{S}^{2} +\Tr_{E} \Omega_{E}^{2},
\end{equation}
y esto es lo mismo que 
\begin{equation}
\langle \Tr_{S} \rho_{S}^{2} \rangle \le \Tr_{S} \langle \rho_{S} \rangle ^{2}  + \Tr_{E} \langle \rho_{E}\rangle^{2}.
\end{equation}

Gracias al resultado \ref{eq:0} se obtiene que
\begin{equation}
\langle \norm{\rho_{S} -\Omega_{S}}_{1} \rangle \le \sqrt{d_{S}(Tr_{E} \langle \rho_{E} \rangle^{2})}.
\end{equation}
Si se define $d_{E}^{eff} \equiv \frac{1}{Tr_{E} \Omega_{E}^{2}}$ como la dimensión efectiva del ambiente en el estado canónico, esto mide la dimensión del espacio en el que el ambiente es más probable de estar. Como $\langle \rho_{E} \rangle_{\phi} = \Omega_{E}$, se concluye que 
\begin{equation}
\langle \norm{\rho_{S} -\Omega_{S}}_{1} \rangle \le \sqrt{\frac{d_{S}}{d_{E}^{eff}}}.
\end{equation}

Ya con esto se tiene el teorema \ref{teorema principal}. Cuando  el ambiente es mucho más grande que el sistema, $\mu$ y $\mu'$  de la ecuación \ref{eq.3} serán pequeñas ($d_{E}^{eff}>>d_{S}$) implicando $\norm{\rho_{S} -\Omega_{S}}_{1} \approx 0$ con alta probabilidad. Aunque ya se llegó a la desigualdad que se quería, se puede notar lo siguiente: sean los valores propios de $\Omega_{E}$ iguales a $\lambda_{E}^{k}$ con su máximo valor propio $\lambda_{E}^{max}$; se ve entonces que 

\begin{align*}
\Tr_{E} \Omega_{E}^{2} &= \sum_{k} (\lambda_{E}^{k})\\
&\leq \lambda_{E}^{max} \sum_{k} \lambda_{E}^{k}\\
&= \max_{\ket{\phi_{E}}} \bra{\phi_{E}} \Tr_{S} \Big( \frac{\mathbbm{1}_{R}}{d_{R}} \Big) \ket{\phi_{E}}\\
&= \max_{\ket{\phi_{E}}} \sum_{s} \bra{s \phi_{E}} \frac{\mathbbm{1}_{R}}{d_{R}} \ket{s \phi_{E}} \\
&\leq \frac{d_{S}}{d_{E}}	
\end{align*}

En conclusión, $d^{eff}_{E} \geq d_{R}/ d_{S}$. Entonces se obtiene

\begin{equation}
\langle \norm{\rho_{S} - \Omega_{S}}_{1} \rangle \leq \sqrt{\frac{d_{S}}{d_{E}^{eff}}} \leq  \sqrt{\frac{d_{S}^{2}}{d_{R}}}.
\end{equation}
Con esto se finaliza la demostración del teorema \ref{teorema principal} en la siguiente sección, se hablará de sus consecuencias físicas.

\section{Significado Físico}

El teorema anterior ya permite hablar del concepto importante que se sigue del trabajo hecho por Popescu \textit{et al}. La idea general de la física es poder dar una relación uno a uno entre las propiedades de un objeto físico y su representación matemática. Con esta correspondencia es posible afirmar que la teoría está completa cuando todas las propiedades que son posibles de medir tienen su semejante en la teoría \cite{Decoherence}. Por ejemplo, en la física clásica, a las cantidades como velocidad y distancia se les asigna los símbolos matemáticos $v$ y $x$; el cuerpo puede ser especificado dando estas dos cantidades en un tiempo determinado. La mecánica clásica nos da un ejemplo sencillo, pero al hacer el tránsito a la mecánica estadística se encuentran perspectivas diferentes que entran en conflicto con esta sencilla idea. 
\\
En sus inicios, la mecánica estadística causó muchas controversias dado que contradecía la idea determinista que Newton y otros habían mostrado como cierta, de que era posible describir la naturaleza de manera predecible. Con la mecánica estadística se introdujo la probabilidad a sistemas que, según Newton, eran deterministas.\footcite{ En este punto se debe hacer claro que la necesidad de recurrir a la probabilidad existía por falta de conocimiento pero no por un indeterminismo intrínseco como en la mecánica cuántica}. Dos propuestas importantes surgieron en busca de una base conceptual para dicha probabilidade: la visión de Gibbs y la de Boltzmann. Gibbs propuso la idea del ensamble, una idea que hasta el día de hoy se sigue utilizando porque da resultados correctos para las propiedades de sistemas termodinámicos.\\
La idea de Gibbs es la siguiente: Se tiene un sistema macroscópico con ciertos parámetros que se pueden medir. Este sistema está compuesto por varias partículas que tienen posiciones y momentos, pero estas propiedades están restringidas por los parámetros macroscópicos. Entonces, como no se puede conocer el microestado del sistema, no se puede medir cada posición y momento de cada partícula; existe una restricción sobre cuál es el microestado dado el macroestado. El ensamble es el conjunto de microestados que cumplen con el macroestado: mientras el microestado cumpla con los parámetros macroscópicos, hará parte del ensamble así el sistema no se encuentre en ese microestado. En teoría, no hay limitación sobre el número de microestados que pertenezcan a un ensamble, éste puede tener infinitos microestados. Esta idea da la base para la función de densidad en el espacio de fase, en el cual se encuentra una cantidad de microestados que no interactúan entre ellos -cada punto en el espacio es un microestado-. Con esto se puede construir la mecánica estadística que se conoce \cite{PathriaStat}. Por el contrario, Boltzmann da un concepción de la mecánica estadística más intuitiva. Él propone $N$ partículas que interactúan entre ellas y cumplen los parámetros macroscópicos. No habla de copias imaginarias de un sistema como en el caso de los ensambles de Gibbs, sino de partículas reales que están en el sistema que se está estudiando. 
\\
Se esperaría que la solución de Boltzmann fuera la que diera los resultados adecuados dada la sencillez de su propuesta, pero es la formulación de Gibbs la que da la termodinámica correcta. E.T Jaynes, en \cite{JaynesEntropies}, muestra las diferencias matemáticas de cada perspectiva y llega a la conclusión de que la formulación de Gibbs da la entropía correcta del sistema sin importar cuál sea el tipo de interacción que tenga el mismo. Además, encuentra que la entropía que sale de la formulación Boltzmanniana no es la misma entropía dada por la termodinámica. La entropía de Boltzmann es correcta cuando no hay interacción entre las partículas.
\\
Ya con la comprobación experimental se debería aceptar la perspectiva de Gibbs como la correcta y dejar a un lado la de Boltzmann, pero esto dejaría a la mecánica estadística en un contexto filosófico frágil: aunque la física busque una correspondencia entre experimento y teoría, no se puede aceptar cualquier teoría solo por tener congruencia con el experimento. La física debe buscar una estabilidad conceptual en sus teorías. Es por esto que, aunque Gibbs encuentre los resultados, no se aceptan sus postulados como marco teórico. Lo que propone Gibbs, aunque matemáticamente aceptable, se basa en todos los microestados en los que el macroestado no se encuentra. Es decir, que para poder determinar la propiedades del estado que se está estudiando, es necesario estudiar a su vez todos los estados en los que el sistema no se encuentra pero podría estar. ¿Por qué para analizar un sistema que se encuentra en un estado definido y exacto se debe examinar los posibles estados infinitos en donde no se encuentra? Si se hace un promedio sobre estos microestados ¿cuál es el significado de este promedio? Este problema ontológico deja la perspectiva de Gibbs en duda, mientras que la de Boltzmann habla del sistema que se examina sin ningún problema de este estilo. 
\\
La lucha entre ambas perspectivas continúa sin resolverse. Lo que se ha mostrado hasta ahora ha sido la propuesta tentativa de unir matemáticamente ambas posiciones dada por Popescu \textit{et al}, en base a que es muy poco probable encontrar un estado lejano del canónico. Por lo tanto -a menos que se tenga un estado bastante especial- se puede asegurar que el subsistema de un universo muy grande, dado por un estado puro (planteamiento de Boltzmann) se comporta de la misma manera que un subsistema de un universo que se encuentre en un estado máximamente mezclado (perspectiva de Gibbs). Esto equivale a decir que, para la mayoría de los estados en un espacio de Hilbert es posible reconciliar ambas perspectivas.
\\
Hay otro punto que agrega mérito a la perspectiva de Popescu \textit{et al}, y es que propone un marco teórico mucho más sólido para la mecánica estadística, al estar éste basado en la mecánica cuántica. Gracias al teorema \ref{teorema principal} se cambia la probabilidad dada por la ignorancia subjetiva por una probabilidad objetiva inherente a la naturaleza, debido al entrelazamiento entre el subsistema y el ambiente, con lo que ya no es imperativo utilizar promedios para fundamentar la mecánica estadística. Este cambio de fundamento permite adicionalmente que ya no sea necesario entrar en el problema de la ergodicidad. 




