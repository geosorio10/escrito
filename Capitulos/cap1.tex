\chapter{Introducción}

\section{Recuento Histórico}
Este recuento histórico sigue los capítulos 1,2 y 3  de \cite{MullerHistory}.
\\
La mecánica estadística es la base conceptual de la termodinámica pero históricamente primero apareció la termodinámica. La termodinámica fue la agrupación de varias ideas en el siglo diecinueve que encerraban varios tipos de experimentos  y nociones que existían desde la antigua Grecia. Aunque las ideas que surgieron en la antigüedad se han ido refinando como ejemplo Klaudios Galenos (133-200 A.C) suponía que la influencia del clima sobre los fluidos del cuerpo podría determinar el carácter de una persona. Así decía que los habitantes del norte frío y húmedo eran salvajes y violentos, al contrario de los habitantes del sur, caliente y seco, eran flácidos y mansos \cite{MullerHistory}. Esto muestra que la idea de temperatura ha sido conocida de alguna u otra manera. 
\\
Ya en el año 1578  Johannis Hasler presentó una tabla de las temperaturas corporales de las personas en relación a la altura en la que vivían. Pero como se conoce ahora mientras se tenga una buena salud no importa la altura se debe tener la misma temperatura corporal. Este error fue debido a los instrumentos de medición usados en esa época. Ya en el inicio del siglo 17 ya se tenía el termómetro. Gracias a este instrumento muchas ideas equivocadas dadas por la subjetividad de los sentidos sobre el calor y el frío se fueron eliminando. Ya en los años 1700 empezaron a aparecer las escalas de temperatura, hubo incluso 18 escalas en algún tiempo. En 1848 William Thompson (Lord Kelvin)  introdujo la escala absoluta o la escala Kelvin. Esta cuenta desde el cero absoluto en adelante, el punto de ebullición del agua a  1 atm es 373.15 Kelvin.
\\
Otra importante parte de la termodinámica es la energía pero en sus inicios no se habla de eso; era calor o fuerza. Pero no se comprendía qué era el calor. La teoría calórica pretendía dar explicación al calor, entre varias propuesta se pueden ver las de Pierre Gassendi (1592-1655) donde proponía que el calor y el frío eran tipos de materia diferente. Consideraba a los átomos del frío como tetraedros y al entrar a un líquido se solidificaría.
\\
Antoine Laurent Lavoisier (1743-1794) consideró al calor como otro elemento, junto con la luz, y lo consideraba como un fluido que llamaba el calórico. Una de las primeras personas en cuestionar la teoría calórica fue Graf Von Rumford(1753-1814), observando unos cañones y cómo cambiaba el calor liberado dependiendo de si estaban afilados  o no. Concluyó que el calor debía ser el mismo que fue administrado debido al movimiento.
\\
Rumford siguió trabajando en su idea del equivalente mecánico del calor, con dos caballos moviendo un cabrestante nota que el calor del barril es igual $"$al de 9 velas grande$"$, más adelante precisó su hallazgo \cite{MullerHistory}. Rumford siguió haciendo experimentos sobre el calor, midió de manera meticulosa el peso del agua antes y después de ser congelada. Encontró que el peso no cambiaba pero aún así se dio calor en el proceso. Entonces concluye que si el calórico existía era imponderable. Pese a los experimentos realizados por Rumford la teoría calórica siguió siendo de gran aceptación durante muchos años.	
\\
Robert Julius Mayer (1814-1878) estudio medicina pero su entusiasmo hacia la física lo guió para hacer experimentos en este campo. La idea principal que tenía Mayer era que la energía se conservaba de forma general, no solo cuando hay trabajo mecánico. Es decir cualquier fenómeno capaz de aportar energía debía tenerse en cuenta al momento de un experimento. Gracias a los estudios hechos por su cuenta sabía que la energía cinética, fuerza viva en sus  palabras, podía convertirse en calor. Experimentalmente llegó a que la caída de un peso a una altura  de 365 metros correspondía a calentar el mismo peso de agua de $0^{\circ}$ a $1^{\circ}$. No es muy exacto pero estuvo bastante cerca, incluso llegó a cambiar la altura a 425 metros luego de que Joule hiciera mejores mediciones.
\\
Mayer tenía ideas bastante originales aunque en general no sabía expresarlas, por falta de experiencia matemática y su aislamiento de la comunidad científica. Pero Mayer fue el primero en hablar sobre máquinas térmicas y decir que el calor absorbido por el vapor era siempre mayor que el calor liberado durante la condensación y su diferencia era trabajo útil. Esta idea se expuso antes que Carnot y Clapeyron \cite{MullerHistory}. Sabía como se manejaba el calor pero no conocía su naturaleza.
\\
James Prescott Joule (1818-1889) proporcionó, en extremo detalle, observaciones sobre el calor y la temperatura. Sus experimentos eran discutidos en sus escritos de forma muy extensa, dando presumibles errores, compensando perdidas, sus experimentos eran tan detallados que algunos de sus artículos se volvieron estándares \cite{MullerHistory}. Es por eso que Mayer revisó sus experimentos respecto a los de Joule. Uno de los aportes de Joule fue que gracias a sus experimentos se podía aceptar la conservación de la energía. 
\\
Pero fue Hermann Ludwig Ferdinand Helmholtz(1821-1894) quien propuso la idea de que lo llamado calor era la energía cinética del movimiento térmico de los átomos. Fue Helmhotlz el primero en dejar el término de un fuerza viva y llamarlo energía \cite{MullerHistory}. El trabajo de Helmholtz fue importante ya que Joule y  Mayer no podía dar una visión clara sobre lo que se llama calor, y divagaban entre calor y fuerza; Helmholtz dejó los conceptos más claros en comparación con ellos dos. 
\\
Todo este proceso histórico fue el camino para poder dar la primera ley de la termodinámica, se puede ver que la historia de la energía no es un desarrollo tan claro y llegar hasta la idea actual no fue para nada rápido ni sencillo. Puede ponerse en contraposición la mecánica cuántica que aunque fue inspirada también de la radiación del cuerpo negro, un tema que en ese entonces era tratado por la termodinámica, se construyó en menos años; aunque con ideas confusas pero su construcción matemática y teórica no fue demorada por siglos. 
\\
A diferencia de la energía, la entropía era un concepto más provocador al momento de darle un sentido microscópico. La historia de la  entropía empieza por los motores térmicos hay especulaciones que en el primer siglo antes de cristo ya existían algunas máquinas que funcionaban con vapor de agua, Hero de Alexandría se especula que hizo una de esa máquinas \cite{MullerHistory}. Pero en el siglo 18 Thomas Newcome y Thomas Savery crearon una máquina de vapor que inicialmente ayudaba a sacar agua de las minas. Fue James Watt(1736-1819) quien mejoró esa máquina de vapor haciendo una que era de 3 a 4 veces más eficiente.
\\
Nicolas Léonard Sadi Carnot (1796-1832) se preguntó sobre que tanto se puede mejorar la eficiencia de una máquina térmica. Carnot publicó un libro donde muestra aseveraciones que intentan resolver la pregunta hecha; Carnot encuentra que: una máquina que trabaja entre dos temperaturas y solo intercambia calor entre ellas, su eficiencia solo depende de la  las temperatura, $e=F(T)dT$ para un delta de temperatura, incluso aunque las máquinas se manejen con agentes diferentes para generar trabajo. 
\\
Carnot seguía creyendo en la teoría calórica para llegar a estas ideas no fue necesario saber que esta teoría estaba incorrecta, aún así sus resultados se mantienen como ciertos. Carnot no pudo encontrar exactamente los valores de la eficiencia. Clapeyron y Kelvin no pudieron tampoco encontrar los valores de esta eficiencia ni por mediciones ni por cálculos. 
\\
Ya en 1850 se estaba asegurando que la teoría calórica estaba mal formulada y se debía hacer algo; Clausius retocó algunas ideas de Carnot y pudo encontrar la eficiencia del ciclo de Carnot. Clausius le dio forma a la termodinámica actual, hasta los cursos actuales de termodinámica siguen un artículo de Clausius que habla de gases ideales y vapor húmedo \cite{MullerHistory}. Clausius amplió sus investigaciones a ciclos no infinitesimales y a procesos no reversibles, él fue quien dio la idea de la entropía y sus propiedades. Con eso propuso la segunda ley de la termodinámica: El calor no puede pasar solo de un cuerpo frío a un cuerpo caliente. Clausius llamó $S=\frac{Q}{T}$ la entropía y vio que esto era lo que se conservaba en un ciclo de Carnot. Pero en términos microscópicos no se conocía el significado de $S$.
\\\
\section{Teoría Cinética}
Paralelamente a mitad del siglo 19 se trabajaba en la teoría cinética de los gases. Esta reposaba en dos suposiciones la primera que los gases eras sistemas mecánicos de muchas partículas idénticas. La segunda era que debido a la gran cantidad de partículas se debía introducir probabilidades para así ver algunas regularidades que salían debido a las configuraciones de las moléculas. Personas como Calusius, Maxwell (1831-1879) y Boltzmann (1844-1906) trabajaron en esta área y produjeron resultados importantes pese a que concordaban con los resultados experimentales, hubo muchas discusiones sobre las hipótesis usadas para llegar a estos resultados. 
\\
Por ejemplo en los trabajos de Clausius se hace uso de los siguientes supuestos para gases en reposo y en equilibrio térmico: Las moléculas que están dentro de un recipiente se encuentran distribuidas con la misma densidad en todo el recipiente, la distribución de velocidades es igual en todo el recipiente, todas las direcciones de velocidad son igual de probables. Estas tres hipótesis son el inicio para ver los sistemas mecánicos con una perspectiva probabilística. 
\\
Maxwell convirtió las ideas de Clausius sobre la  poca dispersión de la distribución de velocidad en algo que se podía calcular. Así que Maxwell propuso en 1859 su ley de distribución
\begin{equation}
f(u,v,w) \Delta u \Delta v \Delta w = A e^{-B(u^{2}+v^{2}+w^{2})}  \Delta u \Delta v \Delta w.
\end{equation}
Donde $f(u,v,w) \Delta u \Delta v \Delta w $ es el número de moléculas entre esos límites de velocidades, cada límite representa un componente de la velocidad.
\\
Botlzmann en 1868 generalizó el resultado de Maxwell, ahora se tiene la misma situación de un gas en equilibrio y en reposo, pero ahora se tiene un campo de fuerza externo actuando sobre las moléculas. Boltzmann tuvo en cuenta que las moléculas eran compuestas de otras partículas  lo cual afecta los diferentes valores de energía potencial. Entonces denotando a $\Delta \tau$ como el rango de variaciones muy pequeñas que puede tener el estado de la molécula, o sea $\Delta \tau= \Delta x \Delta y \Delta z \Delta u \Delta v \Delta w$. La generalización dada por Boltzmann es
\begin{equation}
f(x,y,z,u,v,w) \Delta \tau = \alpha e^{-\beta E} \Delta \tau.
\end{equation}
$E$ es la energía total que tiene la molécula esto es la energía cinética, energía potencial interna y energía potencial externa. Esta generalización es llamada la distribución de Maxwell-Boltzmann. Boltzmann además mostró que cualquier otra distribución bajo la condición de colisiones entre partículas evoluciona hacía la distribución de Maxwell-Boltzmann, él usó el teorema H para concluir esto.

Para hablar del teorema H primero se debe explicar la ecuación de transporte de Boltzmann. La ecuación de transporte de Boltzmann puede ser derivada desde la jerarquía de Bogoliubov-Born-Green-Kirkwood-Yvon \cite{KardarStat} o mirando el problema del número de partículas en un rango del estado de una molécula en el espaico de fase \cite{HuangStat}. Para ambas rutas se debe hacer supuestos para poder seguir con el análisis, esto no se mostrará acá dado que no es pertinente seguir todos los pasos. La ecuación de transporte de Boltzmann describe cómo la distribución de moléculas $f(\vec{r},\vec{p},t)$, donde $\vec{r}$ es la posición y $\vec{p}$ es el momento,  evoluciona en el tiempo. La ecuación es 

\begin{align*}
\quad (\frac{\partial}{\partial t}- \frac{\partial U}{\partial \vec{q}_{1}} \cdot \frac{\partial}{\partial \vec{p}_{1}} +\frac{\vec{p}_{1}}{m} \cdot \frac{\partial}{\partial \vec{q}_{1}})f  &=
\\
- \int d^{3}\vec{p}_{2}d^{2} \Omega |\frac{d \sigma}{d \Omega}| |\vec{v}_{1}-\vec{v}_{2}|[f(\vec{p}_{1},\vec{q}_{1},t)f(\vec{p}_{2},\vec{q}_{1},t) &- f(\vec{p}_{1}',\vec{q}_{1},t)f(\vec{p}_{2}',\vec{q}_{1},t)].
\end{align*}
Esta ecuación se puede leer como \cite{KardarStat}: el término a la izquierda describe el movimiento de una partícula en un potencial U, el término de la derecha es la probabilidad de encontrar una partícula con momento $\vec{p}_{1}$ en $\vec{q}_{1}$ ser alterada por una colisión con una partícula con momento $\vec{p}_{2}$.  La probabilidad de esta colisión está dada por el producto de los factores cinéticos proporcionado por la sección transversal diferencial $ |\frac{d \sigma}{d \Omega}|$, el flujo de partículas incidentes $|\vec{v}_{1}-\vec{v}_{2}|$ y la probabilidad de encontrar dos partículas $[f(\vec{p}_{1},\vec{q}_{1},t)f(\vec{p}_{2},\vec{q}_{1},t)$. El primer término substrae la probabilidad e integra sobre todos lo momentos posibles y el ángulo sólido. El segundo término es la adición del proceso inverso. 
\\
El teorema H dice que si $f$ satisface la ecuación de transporte de Boltzmann, entonces $\frac{dH}{dt} \leq 0$, donde 
\begin{equation}
H(t)= \int d^{3} \vec{p}_{1} d^{3} \vec{q}_{1}  f(\vec{p},\vec{q},t) \ln (f(\vec{p},\vec{q},t)).
\end{equation}
Con este teorema se puede demostrar que la distribución en el equilibrio es la distribución de Maxwell-Boltzmann o sea cuando $t \to \infty$ la distribución  $f(\vec{p},t) \to f_{0}(\vec{p})=  \alpha e^{-\beta E}$ \cite{HuangStat}. Pero hay un punto importante aquí y es algo que también en su época desconcertó a los contemporáneos de Boltzmann, ¿ cómo es posible llegar a una descripción de fenómenos irreversibles que muestran una dirección temporal pero se empezó con una teoría de un gas reversible?. Esto viene dado por las suposiciones echas al derivar la ecuación de transporte de Boltzmann.
\\
Se usa la hipótesis de caos molecular (Stosszahlanzatz), esta dice que después de una colisión las partículas están descorrelacionadas esto quiere decir $F(\vec{r},\vec{p}_{1},\vec{p}_{2},t)=f(\vec{r},\vec{p}_{1},t)f(\vec{r},\vec{p}_{2},t)$. Entonces es en este punto en el que la simetría temporal se rompe y hace que haya una dirección particular para el tiempo. 
El teorema H fue usado por Boltzmann para poder darle una base microscópica a la segunda ley de la termodinámica. La relación es 
\begin{equation}
S(t)=- \frac{H(t)}{k_{B}}
\end{equation}
donde $S$ es la entropía y $k_{B}$ la constante de Boltzmann. Pero también Boltzmann recibió muchas críticas sobre  la posibilidad de asociar a H con la entropía.
\\
Una de las objeciones que recibió fue sobre la posibilidad de poner todas las velocidades de las moléculas de forma opuesta a las dadas inicialmente, esto daría resultados opuestos a los que se esperaban. Si inicialmente se encontraba que H decrecía ahora al invertir las velocidades se halla que H aunmenta, esto significa que hay un caso para el cual la entropía disminuye lo cual va encontra de la segunda ley. 
\\
Otro problema dado por E. Zermelo es que Poincaré había demostrado que en ese modelo cinético de un gas aislado, el sistema secomportaba quasiperiódico. Esto quiere decir que la función H puede ir asumiendo valores más grandes después de un periodo. 
\\
\section{Mecánica Estadística Actual}
Ya más adelante W. Gibbs (1839-1903) con su libro \textit{Elementary Principles of Statistica Mechanics} en 1901 ya propuso la forma actual de hacer física estadística. Él desarrola las ideas que se expusieron en los preliminares, las ideas de ensambles microcanónico y canónico fueron gracias a él. Aunque Gibbs volviera la mecánica estadística más moderna no le quitaba algunos problemas; es más puso en ella otro problema con su idea de ensambles.
\\
Los promedios se encuentran gracias a los ensambles de varias copias idénticas del sistema pero en microestados diferentes que son admisibles por los parámetros macroscópicos. Pero no significa que el sistema que se está estudiando este en todos esos estados es solo un método para poder lograr describir una densidad en el espacio de fase, que luego se usa para poder calcular propiedades del sistema.Entonces entra la pregunta de que tan posible es hablar de copias imaginarias del sistema, sabiendo que solo existe uno. 
\\
En el artículo hecho por E.T Jaynes \cite{JaynesEntropies} se habla de las propuestas dadas por Boltzmann y Gibbs para la entropía. En este artículo pone las diferencias entre cada pero muestra que la entropía dada por Gibbs es la correcta. Siguiendo la notación del artículo,$d\Gamma \equiv d^{3}x_{1}...d^{3}p_{N}$, $d\Gamma_{1} \equiv d^{3}x_{1}d^{3}p_{1}$, $d\Gamma_{-1} \equiv d^{3}x_{2}...d^{3}p_{N}$; se define un ensamble por su función de distribución de $N$ puntos representativos,
\begin{equation}
F_{N}(x_{1},x_{2},..,x_{N};p_{1},p_{2},...,p_{N};t),
\end{equation}
la cual da la densidad de probabilidad del sistema en todo  el espacio de fase. 
\\
La función H de Gibbs esta dada por
\begin{equation}
H_{G}= \int F_{N} \log F_{N} d \Gamma,
\end{equation}
y la función H de Boltzman está dada por 
\begin{equation}
H_{B}=N \int f_{1} log f_{1} d\Gamma_{1}.
\end{equation}
Donde $f_{1}(x_{1},p_{1},t)$ es la probabilidad de densida de una sola partícula, 
\begin{equation}
f_{1}(x_{1},p_{1},t)= \int F_{N} d \Gamma_{-1}.
\end{equation}
En este artículo Jaynes muestra en el teorema 1 que 
\begin{equation}
H_{B} \leq H_{G},
\end{equation}
y la igualdad se cumple solo cuando 
\begin{equation}
F_{N}(x_{1},x_{2},...,x_{N};p_{1},p_{2},...,p_{N})=f_{1}(x_{1},p_{1})...f_{1}(x_{N},p_{N}),
\end{equation}
es decir hay independencia entre las partículas esto es el caso para un gas que no tiene interacción entre partículas, gas ideal. Gracias a esto Jaynes prosigue mostrando que la entropía de Boltzmann, $S_{B}=k_{B}H_{B}$, solo es cierta cuando se habla de un fluido con la misma densidad y temperatura en todo el espacio pero sin fuerzas entre partículas. Mientras la entropía de Gibbs, $S_{G}=k_{B}H_{G}$, es válida para cualquier sistema porque da la entropía fenomenológica de la termodinámica.
\\
Concluye que esta diferencia no puede ser pequeña porque hay interacciones entre partículas muy importantes que afectan ampliamente el resultado. Esto muestra que aunque la idea de Gibbs sobre un ensamble es exótica da los resultados esperados por la termodinámica. Mientras que Boltzmann usando ideas más intuitivas no llega a hacer una conexión con la termodinámica.
\\
La mecánica estadística que introdujo Gibbs tenía como base la idea de la distribución microcanónica, esta es básicamente que: $\rho(q,p)$ es una distribución de densidad en el espacio de fase, la cual es cero en todo el espacio excepto entre $E$ y $E+ \Delta E$, donde $\Delta E$ es bastante pequeña. En esta superficie de energía $\rho$ tiene un valor constante. 
\\
La idea física detrás de esta distribución es bastante simple de exponer. Desde la perspectiva de la teoría de probabilidad cuando no se tiene conocimiento del problema que se quiere tratar se supone que no hay razón para darle un mayor peso a algún resultado que a otro, debido a la ignorancia subjetiva que se tiene. Entonces al no conocer nada del sistema se dice que todos los resultados tienen la misma probabilidad de salir, luego la distribución de probabilidad es constante. 
\\
Luego si tengo un sistema físico del que conozco solo su estado macroscópico, estos parámetros me pueden dar varios posibles estados microscópicos.Ya que no  se tiene más información suponemos que cada posible estado microscópico tiene la misma probabilidad de ser el estado en el que el sistema se encuentra en realidad. Este es uno de los problemas al fundamentar la mecánica estadística porque se basa en la ignorancia subjetiva que se tiene del sistema. Muchos argumentan que las teorías físicas deben ser edificadas en ideas objetivas, y que una rama tan importante de la física se asiente en algo como la ignorancia propia deja mucho que desear.
\\
También aunque esta idea se base en la teoría de la probabilidad también ha sido muy criticada en las matemáticas. Hay preguntas como: si se llegará a conocer un poco más del sistema, ¿ aún sería válida la distribución microcanónica?, ¿ si las probabilidades realmente tiene un peso que se les debería asignar?. En busca de evitar estas preguntas pero no volver a construir toda una teoría lo que se propone es intercambiar el principio de probabilidades iguales por una idea más estable que tenga las mismas implicaciones que ese principio y se vuelva a la mecánica estadística actual.
\\
Este problema ha llamado la atención de varias personas y han existido muchos intentos para poder resolver estos problemas. Se ha intentado basar la mecánica estadística en otras ideas. E.T Jaynes propone una relación entre la mecánica estadística y la teoría clásica de la información \cite{JaynesI},\cite{JaynesII}. 
\\
Jaynes impulsado por la falta de un argumento que conecte los fenómenos microscópicos y los macroscópicos. Procede a estipular que para tener una mecánica estadística libre de objeciones esta debería seguir los siguientes requerimientos: libre de incongruencias matemáticas, no debería tener suposiciones externas arbitrarias y debería ser capaz de describir procesos tanto fuera del equilibrio como en equilibrio. 
\\
Jaynes explica que la segunda condición parece extraña al hablar de una teoría física porque en general se proponen hipótesis que luego intentan ser explicadas. Pone el ejemplo de la unidad de volumen en el espacio de fase que inicialmente fue puesta para poder conseguir los valores correctos de la presión de vapor en equilibrio, luego con la ayuda de la teoría cuántica se vio que esta unidad salía naturalmente de las leyes físicas. Esto hace que Jaynes proponga que la mecánica estadística sea un ejemplo de inferencia estadística. Como la expresión $- \sum p_{i} \log p_{i}$ aparece en la teoría de la información, que es una teoría de inferencia estadística, y en la mecánica estadística, Jaynes expone como crear una conexión entre las dos teorías haciendo que esta fórmula tenga el mismo concepto y así poder aplicar la teoría de la información clásica a la mecánica estadística. Con esto Jaynes muestra un simplificación de la matemática y dice que la mecánica estadística puede afrontar problemas más generales y nuevos problemas físicos.
\\
Toda la perspectiva de Jaynes se basa en el principio de máxima entropía. Para poder entender este principio se plantea un problema que ocurre en muchos casos no solo en la física. Sea $x$ una cantidad discreta que puede tener valores $x_{i}$ con $i=1,2,...,n$. No se saben las probabilidades correspondientes $p_{i}$. Lo único que se  conoce del problema son los promedios de la función $f(x)$,
\begin{equation}
\langle f(x) \rangle =\sum_{i}^{N} p_{i} f(x_{i}).
\end{equation}
Entonces la pregunta que se hace es: ¿ con esta información cuál es el valor esperado de la función $g(x)$?. Esta clase de problemas aparecen en muchas áreas, como la teoría de la información, porque este es un problema de la teoría de la probabilidad. Encontrar las probabilidades con poca información es un problema en el que trabajaron los padres de la probabilidad. El principio dado por Laplace es un intento de resolver el problema, este principio asigna probabilidades iguales a dos eventos. Jaynes dice que a menos que haya una simetría en el problema se encuentran paradojas en los casos continuos. Por eso este tipo de formulaciones se ha dejado de usar en los problemas actuales continua diciendo Jaynes.
\\
Para poder seguir exponiendo el planteamiento de Jaynes se debe entender que la perspectiva que acepta sobre la teoría de la probabilidad es una subjetiva. Esto quiere decir que como J.M. Keynes o H. Jeffreys acepta que las probabilidades son una cuantificación de la ignorancia humana. La probabilidad es solo una medida basada en la información que se tiene sobre el posible resultado que puede salir. Entonces la distribución de probabilidad solo es la representación del estado actual de nuestro conocimiento. \\
En contraposición con la perspectiva objetiva que dice que la probabilidad es la proporción de frecuencias de un experimento, calculando la distribución de probabilidad se está haciendo una predicción que se puede en principio comparar con el experimento. Esta perspectiva acepta las probabilidades como algo externo del humano. Jaynes dice que la visión subjetiva es más general porque las proporciones de frecuencia siempre pueden interpretarse desde esta perspectiva. Además manifiesta que la posición subjetiva acepta interrogantes que para el objetivismo no tienen importancia. 
\\
Shannon en su teoría de la información propuso una función que describía de forma única y sin ambigüedad la cantidad de incertidumbre que tiene una distribución de probabilidad \cite{ShannonInformation}. Esta cantidad es positiva, se incrementa con una incertidumbre decreciente y es aditiva para fuentes de incertidumbres independientes.
\begin{equation}
H(p_{1},...,p_{N})=-k \sum_{i} p_{i} \ln p_{i},
\end{equation}
$k$ es una constante positiva. Aquí Jaynes hace la conexión y es un punto importante. Esta cantidad Shannon la llama entropía pero no es la entropía termodinámica, se dice que Von Neumann le propuso este nombre a Shannon ya que nadie sabía realmente qué era la entropía. Pero Jaynes hace el puente entre las dos teorías diciendo que la entropía termodinámica es la  cantidad de incertidumbre que se tiene del sistema. Entonces esto es lo que quiere decir el principio de la máxima entropía, dadas unas restricciones o sea con una información parcial se debe encontrar la distribución que minimice la incertidumbre. Esto es equivalente a maximizar $H$ bajo las condiciones conocidas. Esta es la forma de llegar a la distribución sin suposiciones arbitrarias que impondríamos bajo conjeturas que no estamos seguros de ser ciertas. 
\\
Jaynes prosigue usando multiplicadores de Lagrange y obtiene los siguientes resultados para un número $m$ de funciones, dado  $\langle f_{r}(x) \rangle = \sum_{i} p_{i} f_{r} (x_{i})$:
\begin{equation} \label{Boltzmann maximum}
p_{i}= \exp \{ -[\lambda_{0}+ \lambda_{1}f_{1}(x_{i})+...+\lambda_{m} f_{m}(x_{i})] \}.
\end{equation}
Donde los $\lambda$'s son los multiplicadores de Lagrange. Además se define la función de partición como
\begin{equation}
Z(\lambda_{1},...,\lambda_{m})=\sum_{i} \exp \{ -[ \lambda_{1}f_{1}(x_{i})+...+\lambda_{m} f_{m}(x_{i})] \}.
\end{equation}
Los multiplicadores de Lagrange se pueden encontrar por
\begin{align*}
\langle f_{r}(x) \rangle  &= - \frac{\partial}{\partial \lambda_{r}} \ln Z, \\
\quad \lambda_{0} &= \ln Z.
\end{align*}
Jaynes argumenta que siguiendo este principio se llega a una distribución de probabilidad imparcial correspondiente a la información del problema, de forma inequívoca y única. También permite la modificación de la distribución de probabilidad si se llega a conocer más información.
\\
Gracias a esto se puede ver los resultados dados por la mecánica estadística fácilmente. Sea $E(\alpha_{1},\alpha_{2},...)$ los niveles de energía de un sistema, donde los $\alpha$'s son parámetros externos como el volumen o potenciales gravitacionales. Si solo se conoce $\langle E \rangle $. Pero por la ecuación \ref{Boltzmann maximum} ya se sabe las probabilidades de los niveles de energías $E_{i}$, esta es la distribución de Maxwell-Boltzmann. Entonces se puede seguir identificando los distintos parámetros de la termodinámica.
\begin{align*}
\lambda_{1} &=\frac{1}{kT}, \\
U-TS &= F(T,\alpha_{1},\alpha_{2},...)=-kT \ln Z(T,\alpha_{1},\alpha_{2},...), \\
S &= -\frac{\partial F}{\partial T}=-k\sum_{i} p_{i} \ln p_{i}, \\
\beta_{i} &= kT \frac{\partial }{\partial \alpha_{i}} \ln Z.
\end{align*}
Las fuerzas $\beta_{i}$ pueden ser la presión, el tensor de estrés, los momentos magnéticos y/o  eléctricos. Se puede también encontrar la distribución gran canónica solo poniendo una nueva restricción sobre el número de partículas. sea $n_{i}$ el número de partículas del tipo $i$ y no se conoce además para especificar el estado del sistema se necesita las $n$'s junto con un nivel de energía $E(\alpha_{1},\alpha_{2},...;n_{1}n_{2}...)$ y se conoce los valores esperados de la energía y cada número de partículas de todos los tipos
\begin{equation}
\langle E \rangle \quad , \quad \langle n_{i} \rangle \quad , \quad i=  \{ 1,2,... \}.
\end{equation} 
la función de partición es la de la gran canónica 
\begin{equation}
Z(\alpha_{1},\alpha_{2},...|\lambda_{1} \lambda_{2} ,...,\beta )= \sum_{n_{1} n_{2}...} \sum_{i} \exp \{ -[ \lambda_{1} n_{1}+\lambda_{2} n_{2}+...+\beta E_{i} (\alpha_{k} | n_{s} ) ] \}.
\end{equation}
La propuesta de Jaynes ha ganado popularidad y evita la pregunta de sobre cuál distribución se está sacando las probabilidades porque como su perspectiva es subjetiva lo único que se está teniendo en cuenta es que se está mirando la ignorancia subjetiva. No se debe crear un ensamble de copias para darle un significado a la probabilidad.

